{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d230734-d44b-430e-b971-0f310e5664fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "Drop schema if exists etl.silver cascade;\n",
    "create schema etl.silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe96477a-072d-4220-877c-815d95969378",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop existing table if exists\n",
    "from pyspark.sql.functions import trim, col, when, upper, row_number\n",
    "from pyspark.sql import Window\n",
    "\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS etl.silver.crm_cust_info\") \n",
    "\n",
    "df_crm_cust_info = (spark.read.table(\"etl.bronze.crm_cust_info\"))\n",
    "                                       \n",
    "w = Window.partitionBy(df_crm_cust_info.cst_id).orderBy(df_crm_cust_info.cst_create_date.desc())\n",
    "                       \n",
    "df_crm_cust_info = (df_crm_cust_info\n",
    "                    .withColumn(\"flag_last\", row_number().over (w)))\n",
    "\n",
    "df = (df_crm_cust_info\n",
    "      .withColumn(\"cst_firstname\", trim(\"cst_firstname\"))\n",
    "      .withColumn(\"cst_lastname\", trim(\"cst_lastname\"))\n",
    "      .withColumn(\"cst_marital_status\", \n",
    "                  when(upper(trim(col(\"cst_marital_status\"))) == \"S\", \"Single\")\n",
    "                 .when(upper(trim(\"cst_marital_status\")) == \"M\", \"Married\")\n",
    "                 .otherwise(\"n/a\"))\n",
    "      .withColumn(\"cst_gndr\", \n",
    "                  when(upper(trim(col(\"cst_gndr\"))) == \"F\", \"Female\")\n",
    "                  .when(upper(trim(col(\"cst_gndr\"))) == \"M\", \"Male\")\n",
    "                  .otherwise(\"n/a\"))\n",
    "      .select(\"cst_id\", \"cst_key\", \"cst_firstname\", \"cst_lastname\", \"cst_marital_status\", \"cst_gndr\", \"cst_create_date\")\n",
    "      .where(col(\"flag_last\") == 1)\n",
    "    )\n",
    "\n",
    "df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"etl.silver.crm_cust_info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82c0955a-489d-486a-bdfe-eab5fca2cec8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import substring, regexp_replace, length, isnull, when, upper, trim, to_date, lead\n",
    "from pyspark.sql import Window\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS etl.silver.crm_prd_info\")\n",
    "\n",
    "df_crm_prd_info = (spark.read.table(\"etl.bronze.crm_prd_info\"))\n",
    "\n",
    "df = (df_crm_prd_info\n",
    "      .withColumn(\"cat_id\", regexp_replace(substring(\"prd_key\", 1, 5), \"-\", \"_\"))\n",
    "      .withColumn(\"prd_key\", substring(\"prd_key\", 7, length(\"prd_key\")))\n",
    "      .withColumn(\"prd_cost\", \n",
    "                  when(col(\"prd_cost\").isNull(), 0)\n",
    "                  .otherwise(col(\"prd_cost\")))\n",
    "      .withColumn(\"prd_line\", \n",
    "                  when(upper(trim(col(\"prd_line\"))) == \"M\", \"Mountain\")\n",
    "                  .when(upper(trim(col(\"prd_line\"))) == \"R\", \"Road\")\n",
    "                  .when(upper(trim(col(\"prd_line\"))) == \"S\", \"Other Sales\")\n",
    "                  .when(upper(trim(col(\"prd_line\"))) == \"T\", \"Touring\")\n",
    "                  .otherwise(\"n/a\"))\n",
    "      .withColumn(\"prd_start_dt\", to_date(\"prd_start_dt\", \"yyyy-MM-dd\"))\n",
    "      .withColumn(\"prd_end_dt\", to_date(lead(\"prd_start_dt\").over(Window.partitionBy(\"prd_key\").orderBy(\"prd_start_dt\")) - 1, \"yyyy-MM-dd\"))\n",
    "\n",
    "      .select(\"prd_id\", \"cat_id\", \"prd_key\", \"prd_nm\", \"prd_cost\", \"prd_line\", \"prd_start_dt\", \"prd_end_dt\"))\n",
    "\n",
    "df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"etl.silver.crm_prd_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8439c7a-7204-4643-92e4-e37ed854ed0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length, to_date, isnull, abs\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS etl.silver.crm_sales_details\")\n",
    "\n",
    "df_crm_sales_details = (spark.read.table(\"etl.bronze.crm_sales_details\"))\n",
    "\n",
    "df = (df_crm_sales_details\n",
    "      .withColumn(\"sls_order_dt\", \n",
    "                  when((col(\"sls_order_dt\") == 0) | (length(col(\"sls_order_dt\")) != 8), None)\n",
    "                  .otherwise(to_date(col(\"sls_order_dt\").cast(\"string\"), \"yyyy-MM-dd\")))\n",
    "      .withColumn(\"sls_ship_dt\", \n",
    "                  when((col(\"sls_ship_dt\") == 0) | (length(col(\"sls_ship_dt\")) != 8), None)\n",
    "                  .otherwise(to_date(col(\"sls_ship_dt\").cast(\"string\"), \"yyyy-MM-dd\")))\n",
    "      .withColumn(\"sls_due_dt\",\n",
    "                  when((col(\"sls_due_dt\") == 0) | (length(col(\"sls_due_dt\")) != 8), None)\n",
    "                  .otherwise(to_date(col(\"sls_due_dt\").cast(\"string\"), \"yyyy-MM-dd\")))\n",
    "      .withColumn(\"sls_sales\",\n",
    "                  when((col(\"sls_sales\").isNull()) | (col(\"sls_sales\") <= 0) | (col(\"sls_sales\") != (col(\"sls_quantity\") * abs(col(\"sls_price\")))), (col(\"sls_quantity\") * abs(col(\"sls_price\")))))\n",
    "      .withColumn(\"sls_price\",\n",
    "                  when((col(\"sls_price\").isNull()) | (col(\"sls_price\") <= 0 ), col(\"sls_sales\") / col(\"sls_quantity\")))\n",
    "      \n",
    "      .select(\"sls_ord_num\", \"sls_prd_key\", \"sls_cust_id\", \"sls_order_dt\", \"sls_ship_dt\", \"sls_due_dt\", \"sls_sales\", \"sls_quantity\", \"sls_price\"))\n",
    "\n",
    "df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"etl.silver.crm_sales_details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca9129f8-6577-4065-84b7-404da7a81f38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_date, upper, trim\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS etl.silver.erp_cust_az12\")\n",
    "\n",
    "df_erp_cust_az12 = (spark.read.table(\"etl.bronze.erp_cust_az12\"))\n",
    "\n",
    "df = (df_erp_cust_az12\n",
    "      .withColumn(\"cid\", \n",
    "                  when(col(\"cid\").like('NAS%'), substring(col(\"cid\"), 4, length(col(\"cid\"))))\n",
    "                  .otherwise(col(\"cid\")))\n",
    "      .withColumn(\"bdate\",\n",
    "                  when(col(\"bdate\") > current_date(), None)\n",
    "                  .otherwise(col(\"bdate\")))\n",
    "      .withColumn(\"gen\", \n",
    "                  when(upper(trim(col(\"gen\"))).isin('F', 'FEMALE'), \"Female\")\n",
    "                  .when(upper(trim(col(\"gen\"))).isin('M', 'MALE'), \"Male\")\n",
    "                  .otherwise(\"n/a\"))\n",
    "      .select(\"cid\", \"bdate\", \"gen\"))\n",
    "\n",
    "df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"etl.silver.erp_cust_az12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c114844f-201c-4209-921d-b180d6a13a3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, trim, isnull, when, col\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS etl.silver.erp_loc_a101\")\n",
    "\n",
    "df_erp_loc_a101 = (spark.read.table(\"etl.bronze.erp_loc_a101\"))\n",
    "\n",
    "df =(df_erp_loc_a101\n",
    "     .withColumn(\"cid\", regexp_replace(\"cid\", '-', ''))\n",
    "     .withColumn(\"cntry\", \n",
    "                 when(trim(col(\"cntry\")) == \"DE\", \"Germany\")\n",
    "                 .when(trim(col(\"cntry\")).isin(\"US\", \"USA\"), \"United States\")\n",
    "                 .when((trim(col(\"cntry\")) == \"\") | (col(\"cntry\").isNull()), \"n/a\")\n",
    "                 .otherwise(trim(col(\"cntry\")))\n",
    "                 )\n",
    "     .select(\"cid\", \"cntry\")\n",
    "     )\n",
    "\n",
    "df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"etl.silver.erp_loc_a101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3ef8cc3-a635-49a1-b2fb-3feef4d496a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS etl.silver.erp_px_cat_g1v2\")\n",
    "\n",
    "df_erp_px_cat_g1v2 = (spark.read.table(\"etl.bronze.erp_px_cat_g1v2\"))\n",
    "\n",
    "df = (df_erp_px_cat_g1v2\n",
    "      .select(\"id\", \"cat\", \"subcat\", \"maintenance\"))\n",
    "\n",
    "df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"etl.silver.erp_px_cat_g1v2\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7452470353996014,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Load Silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}